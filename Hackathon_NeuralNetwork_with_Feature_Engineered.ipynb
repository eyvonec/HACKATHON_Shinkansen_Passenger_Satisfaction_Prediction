{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b31a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic liabraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4110541c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/eyvone/anaconda3/lib/python3.11/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06ecf79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network related libaraies\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac37de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "X_train = pd.read_csv('X_train_wFE.csv').drop(columns='ID', axis=1)\n",
    "y_train = pd.read_csv('Y_train.csv')\n",
    "X_test_initial = pd.read_csv('X_test_wFE.csv')\n",
    "test_ids = X_test_initial['ID']\n",
    "X_test = X_test_initial.drop(columns='ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f937f539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gender', 'Customer_Type', 'Age', 'Type_Travel', 'Travel_Class',\n",
       "       'Travel_Distance', 'Departure_Delay_in_Mins', 'Arrival_Delay_in_Mins',\n",
       "       'Seat_Comfort', 'Seat_Class', 'Arrival_Time_Convenient', 'Catering',\n",
       "       'Platform_Location', 'Onboard_Wifi_Service', 'Onboard_Entertainment',\n",
       "       'Online_Support', 'Ease_of_Online_Booking', 'Onboard_Service',\n",
       "       'Legroom', 'Baggage_Handling', 'CheckIn_Service', 'Cleanliness',\n",
       "       'Online_Boarding', 'Travel_Distance Departure_Delay_in_Mins',\n",
       "       'Travel_Distance Arrival_Delay_in_Mins',\n",
       "       'Departure_Delay_in_Mins Arrival_Delay_in_Mins',\n",
       "       'Online_Support Ease_of_Online_Booking',\n",
       "       'Online_Support Onboard_Service', 'Online_Support Online_Boarding',\n",
       "       'Ease_of_Online_Booking Onboard_Service',\n",
       "       'Ease_of_Online_Booking Online_Boarding',\n",
       "       'Onboard_Service Online_Boarding', 'Seat_Comfort Seat_Class',\n",
       "       'Seat_Comfort Legroom', 'Seat_Class Legroom',\n",
       "       'Onboard_Wifi_Service Onboard_Entertainment',\n",
       "       'Baggage_Handling CheckIn_Service', 'Gender Customer_Type',\n",
       "       'Gender Age', 'Gender Type_Travel', 'Customer_Type Age',\n",
       "       'Customer_Type Type_Travel', 'Age Type_Travel'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce919b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35602 entries, 0 to 35601\n",
      "Data columns (total 43 columns):\n",
      " #   Column                                         Non-Null Count  Dtype  \n",
      "---  ------                                         --------------  -----  \n",
      " 0   Gender                                         35602 non-null  float64\n",
      " 1   Customer_Type                                  35602 non-null  float64\n",
      " 2   Age                                            35602 non-null  float64\n",
      " 3   Type_Travel                                    35602 non-null  float64\n",
      " 4   Travel_Class                                   35602 non-null  int64  \n",
      " 5   Travel_Distance                                35602 non-null  int64  \n",
      " 6   Departure_Delay_in_Mins                        35602 non-null  float64\n",
      " 7   Arrival_Delay_in_Mins                          35602 non-null  float64\n",
      " 8   Seat_Comfort                                   35602 non-null  float64\n",
      " 9   Seat_Class                                     35602 non-null  int64  \n",
      " 10  Arrival_Time_Convenient                        35602 non-null  float64\n",
      " 11  Catering                                       35602 non-null  float64\n",
      " 12  Platform_Location                              35602 non-null  float64\n",
      " 13  Onboard_Wifi_Service                           35602 non-null  float64\n",
      " 14  Onboard_Entertainment                          35602 non-null  float64\n",
      " 15  Online_Support                                 35602 non-null  float64\n",
      " 16  Ease_of_Online_Booking                         35602 non-null  float64\n",
      " 17  Onboard_Service                                35602 non-null  float64\n",
      " 18  Legroom                                        35602 non-null  float64\n",
      " 19  Baggage_Handling                               35602 non-null  float64\n",
      " 20  CheckIn_Service                                35602 non-null  float64\n",
      " 21  Cleanliness                                    35602 non-null  float64\n",
      " 22  Online_Boarding                                35602 non-null  float64\n",
      " 23  Travel_Distance Departure_Delay_in_Mins        35602 non-null  float64\n",
      " 24  Travel_Distance Arrival_Delay_in_Mins          35602 non-null  float64\n",
      " 25  Departure_Delay_in_Mins Arrival_Delay_in_Mins  35602 non-null  float64\n",
      " 26  Online_Support Ease_of_Online_Booking          35602 non-null  float64\n",
      " 27  Online_Support Onboard_Service                 35602 non-null  float64\n",
      " 28  Online_Support Online_Boarding                 35602 non-null  float64\n",
      " 29  Ease_of_Online_Booking Onboard_Service         35602 non-null  float64\n",
      " 30  Ease_of_Online_Booking Online_Boarding         35602 non-null  float64\n",
      " 31  Onboard_Service Online_Boarding                35602 non-null  float64\n",
      " 32  Seat_Comfort Seat_Class                        35602 non-null  float64\n",
      " 33  Seat_Comfort Legroom                           35602 non-null  float64\n",
      " 34  Seat_Class Legroom                             35602 non-null  float64\n",
      " 35  Onboard_Wifi_Service Onboard_Entertainment     35602 non-null  float64\n",
      " 36  Baggage_Handling CheckIn_Service               35602 non-null  float64\n",
      " 37  Gender Customer_Type                           35602 non-null  float64\n",
      " 38  Gender Age                                     35602 non-null  float64\n",
      " 39  Gender Type_Travel                             35602 non-null  float64\n",
      " 40  Customer_Type Age                              35602 non-null  float64\n",
      " 41  Customer_Type Type_Travel                      35602 non-null  float64\n",
      " 42  Age Type_Travel                                35602 non-null  float64\n",
      "dtypes: float64(40), int64(3)\n",
      "memory usage: 11.7 MB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dc76925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2279/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 242us/step - accuracy: 0.8687 - loss: 0.2995\n",
      "Epoch 1: val_accuracy improved from -inf to 0.92191, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309us/step - accuracy: 0.8698 - loss: 0.2972 - val_accuracy: 0.9219 - val_loss: 0.1903\n",
      "Epoch 2/50\n",
      "\u001b[1m2331/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 258us/step - accuracy: 0.9236 - loss: 0.1811\n",
      "Epoch 2: val_accuracy improved from 0.92191 to 0.93139, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326us/step - accuracy: 0.9237 - loss: 0.1810 - val_accuracy: 0.9314 - val_loss: 0.1698\n",
      "Epoch 3/50\n",
      "\u001b[1m2328/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 280us/step - accuracy: 0.9325 - loss: 0.1590\n",
      "Epoch 3: val_accuracy improved from 0.93139 to 0.93537, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330us/step - accuracy: 0.9325 - loss: 0.1589 - val_accuracy: 0.9354 - val_loss: 0.1574\n",
      "Epoch 4/50\n",
      "\u001b[1m2260/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 244us/step - accuracy: 0.9374 - loss: 0.1461\n",
      "Epoch 4: val_accuracy improved from 0.93537 to 0.93807, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290us/step - accuracy: 0.9374 - loss: 0.1459 - val_accuracy: 0.9381 - val_loss: 0.1502\n",
      "Epoch 5/50\n",
      "\u001b[1m2286/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 241us/step - accuracy: 0.9418 - loss: 0.1366\n",
      "Epoch 5: val_accuracy improved from 0.93807 to 0.94024, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287us/step - accuracy: 0.9418 - loss: 0.1365 - val_accuracy: 0.9402 - val_loss: 0.1444\n",
      "Epoch 6/50\n",
      "\u001b[1m2268/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 243us/step - accuracy: 0.9446 - loss: 0.1309\n",
      "Epoch 6: val_accuracy improved from 0.94024 to 0.94241, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289us/step - accuracy: 0.9446 - loss: 0.1308 - val_accuracy: 0.9424 - val_loss: 0.1406\n",
      "Epoch 7/50\n",
      "\u001b[1m2276/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 242us/step - accuracy: 0.9457 - loss: 0.1258\n",
      "Epoch 7: val_accuracy did not improve from 0.94241\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287us/step - accuracy: 0.9458 - loss: 0.1257 - val_accuracy: 0.9415 - val_loss: 0.1405\n",
      "Epoch 8/50\n",
      "\u001b[1m2178/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 253us/step - accuracy: 0.9471 - loss: 0.1227\n",
      "Epoch 8: val_accuracy improved from 0.94241 to 0.94326, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300us/step - accuracy: 0.9472 - loss: 0.1225 - val_accuracy: 0.9433 - val_loss: 0.1377\n",
      "Epoch 9/50\n",
      "\u001b[1m2204/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 250us/step - accuracy: 0.9487 - loss: 0.1190\n",
      "Epoch 9: val_accuracy improved from 0.94326 to 0.94459, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296us/step - accuracy: 0.9488 - loss: 0.1188 - val_accuracy: 0.9446 - val_loss: 0.1342\n",
      "Epoch 10/50\n",
      "\u001b[1m2322/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 259us/step - accuracy: 0.9499 - loss: 0.1159\n",
      "Epoch 10: val_accuracy improved from 0.94459 to 0.94485, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 308us/step - accuracy: 0.9499 - loss: 0.1159 - val_accuracy: 0.9449 - val_loss: 0.1331\n",
      "Epoch 11/50\n",
      "\u001b[1m2231/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 247us/step - accuracy: 0.9507 - loss: 0.1135\n",
      "Epoch 11: val_accuracy did not improve from 0.94485\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291us/step - accuracy: 0.9507 - loss: 0.1134 - val_accuracy: 0.9447 - val_loss: 0.1335\n",
      "Epoch 12/50\n",
      "\u001b[1m2257/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 244us/step - accuracy: 0.9513 - loss: 0.1124\n",
      "Epoch 12: val_accuracy improved from 0.94485 to 0.94522, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291us/step - accuracy: 0.9513 - loss: 0.1123 - val_accuracy: 0.9452 - val_loss: 0.1331\n",
      "Epoch 13/50\n",
      "\u001b[1m2235/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 247us/step - accuracy: 0.9522 - loss: 0.1105\n",
      "Epoch 13: val_accuracy improved from 0.94522 to 0.94554, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 293us/step - accuracy: 0.9522 - loss: 0.1104 - val_accuracy: 0.9455 - val_loss: 0.1328\n",
      "Epoch 14/50\n",
      "\u001b[1m2241/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 246us/step - accuracy: 0.9533 - loss: 0.1083\n",
      "Epoch 14: val_accuracy improved from 0.94554 to 0.94602, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 292us/step - accuracy: 0.9533 - loss: 0.1082 - val_accuracy: 0.9460 - val_loss: 0.1329\n",
      "Epoch 15/50\n",
      "\u001b[1m2199/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 251us/step - accuracy: 0.9542 - loss: 0.1071\n",
      "Epoch 15: val_accuracy improved from 0.94602 to 0.94644, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299us/step - accuracy: 0.9542 - loss: 0.1070 - val_accuracy: 0.9464 - val_loss: 0.1319\n",
      "Epoch 16/50\n",
      "\u001b[1m2289/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 241us/step - accuracy: 0.9547 - loss: 0.1054\n",
      "Epoch 16: val_accuracy did not improve from 0.94644\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 285us/step - accuracy: 0.9547 - loss: 0.1053 - val_accuracy: 0.9459 - val_loss: 0.1320\n",
      "Epoch 17/50\n",
      "\u001b[1m2289/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 241us/step - accuracy: 0.9554 - loss: 0.1040\n",
      "Epoch 17: val_accuracy did not improve from 0.94644\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 286us/step - accuracy: 0.9554 - loss: 0.1040 - val_accuracy: 0.9460 - val_loss: 0.1334\n",
      "Epoch 18/50\n",
      "\u001b[1m2292/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 241us/step - accuracy: 0.9558 - loss: 0.1035\n",
      "Epoch 18: val_accuracy improved from 0.94644 to 0.94655, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 286us/step - accuracy: 0.9558 - loss: 0.1035 - val_accuracy: 0.9465 - val_loss: 0.1326\n",
      "Epoch 19/50\n",
      "\u001b[1m2267/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 244us/step - accuracy: 0.9564 - loss: 0.1016\n",
      "Epoch 19: val_accuracy did not improve from 0.94655\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287us/step - accuracy: 0.9564 - loss: 0.1015 - val_accuracy: 0.9462 - val_loss: 0.1315\n",
      "Epoch 20/50\n",
      "\u001b[1m2285/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 241us/step - accuracy: 0.9574 - loss: 0.1007\n",
      "Epoch 20: val_accuracy did not improve from 0.94655\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 285us/step - accuracy: 0.9574 - loss: 0.1007 - val_accuracy: 0.9464 - val_loss: 0.1339\n",
      "Epoch 21/50\n",
      "\u001b[1m2272/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 243us/step - accuracy: 0.9570 - loss: 0.0999\n",
      "Epoch 21: val_accuracy improved from 0.94655 to 0.94676, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289us/step - accuracy: 0.9570 - loss: 0.0999 - val_accuracy: 0.9468 - val_loss: 0.1323\n",
      "Epoch 22/50\n",
      "\u001b[1m2175/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 254us/step - accuracy: 0.9573 - loss: 0.0992\n",
      "Epoch 22: val_accuracy did not improve from 0.94676\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299us/step - accuracy: 0.9574 - loss: 0.0991 - val_accuracy: 0.9462 - val_loss: 0.1345\n",
      "Epoch 23/50\n",
      "\u001b[1m2178/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 253us/step - accuracy: 0.9575 - loss: 0.0986\n",
      "Epoch 23: val_accuracy did not improve from 0.94676\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299us/step - accuracy: 0.9575 - loss: 0.0985 - val_accuracy: 0.9462 - val_loss: 0.1330\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2190/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 252us/step - accuracy: 0.9581 - loss: 0.0975\n",
      "Epoch 24: val_accuracy did not improve from 0.94676\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297us/step - accuracy: 0.9581 - loss: 0.0974 - val_accuracy: 0.9452 - val_loss: 0.1364\n",
      "Epoch 25/50\n",
      "\u001b[1m2240/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 246us/step - accuracy: 0.9583 - loss: 0.0974\n",
      "Epoch 25: val_accuracy did not improve from 0.94676\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 292us/step - accuracy: 0.9583 - loss: 0.0973 - val_accuracy: 0.9461 - val_loss: 0.1369\n",
      "Epoch 26/50\n",
      "\u001b[1m2206/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 250us/step - accuracy: 0.9580 - loss: 0.0966\n",
      "Epoch 26: val_accuracy improved from 0.94676 to 0.94697, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298us/step - accuracy: 0.9580 - loss: 0.0965 - val_accuracy: 0.9470 - val_loss: 0.1364\n",
      "Epoch 27/50\n",
      "\u001b[1m2200/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 251us/step - accuracy: 0.9580 - loss: 0.0958\n",
      "Epoch 27: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 295us/step - accuracy: 0.9580 - loss: 0.0957 - val_accuracy: 0.9465 - val_loss: 0.1380\n",
      "Epoch 28/50\n",
      "\u001b[1m2220/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 248us/step - accuracy: 0.9586 - loss: 0.0948\n",
      "Epoch 28: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296us/step - accuracy: 0.9586 - loss: 0.0947 - val_accuracy: 0.9455 - val_loss: 0.1385\n",
      "Epoch 29/50\n",
      "\u001b[1m2337/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 257us/step - accuracy: 0.9588 - loss: 0.0940\n",
      "Epoch 29: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303us/step - accuracy: 0.9588 - loss: 0.0940 - val_accuracy: 0.9447 - val_loss: 0.1394\n",
      "Epoch 30/50\n",
      "\u001b[1m2215/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 249us/step - accuracy: 0.9591 - loss: 0.0935\n",
      "Epoch 30: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296us/step - accuracy: 0.9591 - loss: 0.0934 - val_accuracy: 0.9458 - val_loss: 0.1404\n",
      "Epoch 31/50\n",
      "\u001b[1m2172/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 254us/step - accuracy: 0.9598 - loss: 0.0933\n",
      "Epoch 31: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300us/step - accuracy: 0.9598 - loss: 0.0932 - val_accuracy: 0.9460 - val_loss: 0.1405\n",
      "Epoch 32/50\n",
      "\u001b[1m2194/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 251us/step - accuracy: 0.9598 - loss: 0.0925\n",
      "Epoch 32: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296us/step - accuracy: 0.9598 - loss: 0.0924 - val_accuracy: 0.9453 - val_loss: 0.1411\n",
      "Epoch 33/50\n",
      "\u001b[1m2170/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 254us/step - accuracy: 0.9605 - loss: 0.0919\n",
      "Epoch 33: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299us/step - accuracy: 0.9605 - loss: 0.0918 - val_accuracy: 0.9461 - val_loss: 0.1420\n",
      "Epoch 34/50\n",
      "\u001b[1m2226/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 248us/step - accuracy: 0.9603 - loss: 0.0914\n",
      "Epoch 34: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 292us/step - accuracy: 0.9603 - loss: 0.0913 - val_accuracy: 0.9465 - val_loss: 0.1399\n",
      "Epoch 35/50\n",
      "\u001b[1m2205/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 250us/step - accuracy: 0.9611 - loss: 0.0897\n",
      "Epoch 35: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 295us/step - accuracy: 0.9611 - loss: 0.0897 - val_accuracy: 0.9461 - val_loss: 0.1423\n",
      "Epoch 36/50\n",
      "\u001b[1m2167/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 255us/step - accuracy: 0.9615 - loss: 0.0896\n",
      "Epoch 36: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300us/step - accuracy: 0.9615 - loss: 0.0895 - val_accuracy: 0.9456 - val_loss: 0.1428\n",
      "Epoch 37/50\n",
      "\u001b[1m2180/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 253us/step - accuracy: 0.9612 - loss: 0.0916\n",
      "Epoch 37: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300us/step - accuracy: 0.9612 - loss: 0.0914 - val_accuracy: 0.9450 - val_loss: 0.1452\n",
      "Epoch 38/50\n",
      "\u001b[1m2311/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 261us/step - accuracy: 0.9616 - loss: 0.0885\n",
      "Epoch 38: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 307us/step - accuracy: 0.9616 - loss: 0.0885 - val_accuracy: 0.9461 - val_loss: 0.1450\n",
      "Epoch 39/50\n",
      "\u001b[1m2163/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 255us/step - accuracy: 0.9617 - loss: 0.0895\n",
      "Epoch 39: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300us/step - accuracy: 0.9617 - loss: 0.0894 - val_accuracy: 0.9461 - val_loss: 0.1447\n",
      "Epoch 40/50\n",
      "\u001b[1m2199/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 251us/step - accuracy: 0.9627 - loss: 0.0868\n",
      "Epoch 40: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298us/step - accuracy: 0.9627 - loss: 0.0868 - val_accuracy: 0.9463 - val_loss: 0.1461\n",
      "Epoch 41/50\n",
      "\u001b[1m2350/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 256us/step - accuracy: 0.9629 - loss: 0.0881\n",
      "Epoch 41: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 304us/step - accuracy: 0.9629 - loss: 0.0881 - val_accuracy: 0.9452 - val_loss: 0.1468\n",
      "Epoch 42/50\n",
      "\u001b[1m2178/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 253us/step - accuracy: 0.9628 - loss: 0.0863\n",
      "Epoch 42: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300us/step - accuracy: 0.9628 - loss: 0.0863 - val_accuracy: 0.9460 - val_loss: 0.1477\n",
      "Epoch 43/50\n",
      "\u001b[1m2187/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 252us/step - accuracy: 0.9635 - loss: 0.0858\n",
      "Epoch 43: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297us/step - accuracy: 0.9635 - loss: 0.0857 - val_accuracy: 0.9459 - val_loss: 0.1480\n",
      "Epoch 44/50\n",
      "\u001b[1m2339/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 257us/step - accuracy: 0.9634 - loss: 0.0859\n",
      "Epoch 44: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 304us/step - accuracy: 0.9634 - loss: 0.0859 - val_accuracy: 0.9463 - val_loss: 0.1462\n",
      "Epoch 45/50\n",
      "\u001b[1m2169/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 254us/step - accuracy: 0.9643 - loss: 0.0841\n",
      "Epoch 45: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299us/step - accuracy: 0.9642 - loss: 0.0841 - val_accuracy: 0.9461 - val_loss: 0.1476\n",
      "Epoch 46/50\n",
      "\u001b[1m2208/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 250us/step - accuracy: 0.9642 - loss: 0.0842\n",
      "Epoch 46: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 295us/step - accuracy: 0.9642 - loss: 0.0842 - val_accuracy: 0.9455 - val_loss: 0.1513\n",
      "Epoch 47/50\n",
      "\u001b[1m2348/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 256us/step - accuracy: 0.9636 - loss: 0.0841\n",
      "Epoch 47: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303us/step - accuracy: 0.9636 - loss: 0.0841 - val_accuracy: 0.9468 - val_loss: 0.1477\n",
      "Epoch 48/50\n",
      "\u001b[1m2166/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 255us/step - accuracy: 0.9643 - loss: 0.0829\n",
      "Epoch 48: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300us/step - accuracy: 0.9642 - loss: 0.0830 - val_accuracy: 0.9462 - val_loss: 0.1490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "\u001b[1m2248/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 245us/step - accuracy: 0.9639 - loss: 0.0830\n",
      "Epoch 49: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290us/step - accuracy: 0.9639 - loss: 0.0831 - val_accuracy: 0.9462 - val_loss: 0.1510\n",
      "Epoch 50/50\n",
      "\u001b[1m2219/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 249us/step - accuracy: 0.9647 - loss: 0.0831\n",
      "Epoch 50: val_accuracy did not improve from 0.94697\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 294us/step - accuracy: 0.9646 - loss: 0.0831 - val_accuracy: 0.9463 - val_loss: 0.1474\n",
      "\u001b[1m1113/1113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190us/step\n"
     ]
    }
   ],
   "source": [
    "# Scale the features (fit on X_train and transform both X_train and X_test)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Set a random seed for NumPy and TensorFlow to ensure reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(X_train_scaled.shape[1],), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Setup the ModelCheckpoint callback to save the best model\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',  # Specify .keras extension\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with validation split to monitor performance\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[model_checkpoint],  # Include the checkpoint in the callbacks\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Load the best model saved by ModelCheckpoint\n",
    "best_model = tf.keras.models.load_model('best_model.keras')\n",
    "\n",
    "# Use the best model to make predictions on the test set\n",
    "predictions = best_model.predict(X_test_scaled)\n",
    "predictions = (predictions > 0.5).astype(int)  # Convert probabilities to binary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00de308e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e882c8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1113/1113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191us/step\n"
     ]
    }
   ],
   "source": [
    "# Predict the result\n",
    "predictions = model.predict(X_test_scaled)\n",
    "predictions = (predictions > 0.5).astype(int)  # Convert probabilities to binary output\n",
    "\n",
    "# Combine IDs with predictions for a submission\n",
    "results_df = pd.DataFrame({\n",
    "    'ID': test_ids,\n",
    "    'Overall_Experience': predictions.ravel()  # Adjust based on your model output structure\n",
    "})\n",
    "\n",
    "# Save or return results\n",
    "results_df.to_csv('submisson3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "391dcb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Overall_Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99900001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99900002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99900003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99900004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99900005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35597</th>\n",
       "      <td>99935598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35598</th>\n",
       "      <td>99935599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35599</th>\n",
       "      <td>99935600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35600</th>\n",
       "      <td>99935601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35601</th>\n",
       "      <td>99935602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35602 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  Overall_Experience\n",
       "0      99900001                   1\n",
       "1      99900002                   1\n",
       "2      99900003                   1\n",
       "3      99900004                   0\n",
       "4      99900005                   1\n",
       "...         ...                 ...\n",
       "35597  99935598                   0\n",
       "35598  99935599                   1\n",
       "35599  99935600                   0\n",
       "35600  99935601                   1\n",
       "35601  99935602                   0\n",
       "\n",
       "[35602 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57c66c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35602, 44)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_initial.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64de02b6",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d092f32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Obtaining dependency information for keras-tuner from https://files.pythonhosted.org/packages/db/5d/945296512980b0827e93418514c8be9236baa6f0a1e8ca8be3a2026665b0/keras_tuner-1.4.7-py3-none-any.whl.metadata\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras-tuner) (3.3.2)\n",
      "Requirement already satisfied: packaging in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras-tuner) (23.1)\n",
      "Requirement already satisfied: requests in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras-tuner) (2.31.0)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Obtaining dependency information for kt-legacy from https://files.pythonhosted.org/packages/16/53/aca9f36da2516db008017db85a1f3cafaee0efc5fc7a25d94c909651792f/kt_legacy-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: absl-py in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: numpy in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (1.24.3)\n",
      "Requirement already satisfied: rich in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (3.11.0)\n",
      "Requirement already satisfied: optree in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (0.3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from requests->keras-tuner) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from requests->keras-tuner) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from optree->keras->keras-tuner) (4.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from rich->keras->keras-tuner) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from rich->keras->keras-tuner) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.0)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5e431cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 Complete [00h 01m 26s]\n",
      "val_accuracy: 0.9410362243652344\n",
      "\n",
      "Best val_accuracy So Far: 0.9483735859394073\n",
      "Total elapsed time: 00h 03m 52s\n",
      "\n",
      "The best number of layers: 4\n",
      "The best number of units per layer: [192, 288, 128, 416]\n",
      "The best activations per layer: ['tanh', 'relu', 'tanh', 'sigmoid']\n",
      "The best learning rate for the optimizer: 0.000976698895553929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner import HyperModel\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "class MyHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "    \n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.InputLayer(input_shape=self.input_shape))\n",
    "        \n",
    "        # Tune the number of layers, now allowing up to 5 dense layers\n",
    "        for i in range(hp.Int('num_layers', 1, 5)): \n",
    "            model.add(layers.Dense(\n",
    "                units=hp.Int('units_' + str(i), min_value=32, max_value=512, step=32),\n",
    "                activation=hp.Choice('activation_' + str(i), values=['relu', 'tanh', 'sigmoid'])\n",
    "            ))\n",
    "        \n",
    "        model.add(layers.Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(\n",
    "                hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "# Assuming X_train_scaled and y_train are already defined\n",
    "input_shape = (X_train_scaled.shape[1],)\n",
    "\n",
    "hypermodel = MyHyperModel(input_shape=input_shape)\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=6,  # Set a reasonable number of trials to find the best hyperparameters\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir_FE',  # Directory to store logs\n",
    "    project_name='keras_tuner_demo_FE'\n",
    ")\n",
    "\n",
    "# Start tuning\n",
    "tuner.search(X_train_scaled, y_train, epochs=10, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The best number of layers: {best_hps.get('num_layers')}\n",
    "The best number of units per layer: {[best_hps.get('units_' + str(i)) for i in range(best_hps.get('num_layers'))]}\n",
    "The best activations per layer: {[best_hps.get('activation_' + str(i)) for i in range(best_hps.get('num_layers'))]}\n",
    "The best learning rate for the optimizer: {best_hps.get('learning_rate')}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb11d69",
   "metadata": {},
   "source": [
    "### Optimized Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a078788c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2324/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8898 - loss: 0.2610\n",
      "Epoch 1: val_accuracy improved from -inf to 0.92276, saving model to best_model_optimized.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8902 - loss: 0.2603 - val_accuracy: 0.9228 - val_loss: 0.1877\n",
      "Epoch 2/50\n",
      "\u001b[1m2338/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.9315 - loss: 0.1648\n",
      "Epoch 2: val_accuracy improved from 0.92276 to 0.93563, saving model to best_model_optimized.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9316 - loss: 0.1647 - val_accuracy: 0.9356 - val_loss: 0.1589\n",
      "Epoch 3/50\n",
      "\u001b[1m2356/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9415 - loss: 0.1382\n",
      "Epoch 3: val_accuracy improved from 0.93563 to 0.94067, saving model to best_model_optimized.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9415 - loss: 0.1382 - val_accuracy: 0.9407 - val_loss: 0.1435\n",
      "Epoch 4/50\n",
      "\u001b[1m2323/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.9453 - loss: 0.1261\n",
      "Epoch 4: val_accuracy did not improve from 0.94067\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9453 - loss: 0.1260 - val_accuracy: 0.9334 - val_loss: 0.1579\n",
      "Epoch 5/50\n",
      "\u001b[1m2348/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.9491 - loss: 0.1171\n",
      "Epoch 5: val_accuracy improved from 0.94067 to 0.94416, saving model to best_model_optimized.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9491 - loss: 0.1171 - val_accuracy: 0.9442 - val_loss: 0.1313\n",
      "Epoch 6/50\n",
      "\u001b[1m2349/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.9519 - loss: 0.1095\n",
      "Epoch 6: val_accuracy improved from 0.94416 to 0.94670, saving model to best_model_optimized.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9519 - loss: 0.1095 - val_accuracy: 0.9467 - val_loss: 0.1317\n",
      "Epoch 7/50\n",
      "\u001b[1m2347/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.9542 - loss: 0.1058\n",
      "Epoch 7: val_accuracy improved from 0.94670 to 0.94766, saving model to best_model_optimized.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9542 - loss: 0.1057 - val_accuracy: 0.9477 - val_loss: 0.1312\n",
      "Epoch 8/50\n",
      "\u001b[1m2334/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.9569 - loss: 0.1002\n",
      "Epoch 8: val_accuracy did not improve from 0.94766\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9569 - loss: 0.1002 - val_accuracy: 0.9475 - val_loss: 0.1333\n",
      "Epoch 9/50\n",
      "\u001b[1m2346/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.9590 - loss: 0.0955\n",
      "Epoch 9: val_accuracy improved from 0.94766 to 0.94919, saving model to best_model_optimized.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9590 - loss: 0.0955 - val_accuracy: 0.9492 - val_loss: 0.1295\n",
      "Epoch 10/50\n",
      "\u001b[1m2335/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 0.9593 - loss: 0.0913\n",
      "Epoch 10: val_accuracy did not improve from 0.94919\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9593 - loss: 0.0912 - val_accuracy: 0.9483 - val_loss: 0.1358\n",
      "Epoch 11/50\n",
      "\u001b[1m2312/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9619 - loss: 0.0905\n",
      "Epoch 11: val_accuracy did not improve from 0.94919\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9619 - loss: 0.0904 - val_accuracy: 0.9492 - val_loss: 0.1382\n",
      "Epoch 12/50\n",
      "\u001b[1m2317/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9622 - loss: 0.0836\n",
      "Epoch 12: val_accuracy did not improve from 0.94919\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9622 - loss: 0.0836 - val_accuracy: 0.9491 - val_loss: 0.1448\n",
      "Epoch 13/50\n",
      "\u001b[1m2316/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9651 - loss: 0.0805\n",
      "Epoch 13: val_accuracy did not improve from 0.94919\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9651 - loss: 0.0805 - val_accuracy: 0.9474 - val_loss: 0.1467\n",
      "Epoch 14/50\n",
      "\u001b[1m2334/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9649 - loss: 0.0772\n",
      "Epoch 14: val_accuracy improved from 0.94919 to 0.94972, saving model to best_model_optimized.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9649 - loss: 0.0772 - val_accuracy: 0.9497 - val_loss: 0.1488\n",
      "Epoch 15/50\n",
      "\u001b[1m2354/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9660 - loss: 0.0755\n",
      "Epoch 15: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9660 - loss: 0.0755 - val_accuracy: 0.9489 - val_loss: 0.1620\n",
      "Epoch 16/50\n",
      "\u001b[1m2335/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9680 - loss: 0.0713\n",
      "Epoch 16: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9680 - loss: 0.0713 - val_accuracy: 0.9474 - val_loss: 0.1605\n",
      "Epoch 17/50\n",
      "\u001b[1m2349/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.9688 - loss: 0.0717\n",
      "Epoch 17: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9689 - loss: 0.0717 - val_accuracy: 0.9470 - val_loss: 0.1723\n",
      "Epoch 18/50\n",
      "\u001b[1m2340/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.9688 - loss: 0.0691\n",
      "Epoch 18: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9688 - loss: 0.0690 - val_accuracy: 0.9443 - val_loss: 0.1725\n",
      "Epoch 19/50\n",
      "\u001b[1m2341/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9707 - loss: 0.0648\n",
      "Epoch 19: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9708 - loss: 0.0648 - val_accuracy: 0.9494 - val_loss: 0.1796\n",
      "Epoch 20/50\n",
      "\u001b[1m2341/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9719 - loss: 0.0628\n",
      "Epoch 20: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9719 - loss: 0.0628 - val_accuracy: 0.9490 - val_loss: 0.1822\n",
      "Epoch 21/50\n",
      "\u001b[1m2358/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9715 - loss: 0.0637\n",
      "Epoch 21: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9715 - loss: 0.0637 - val_accuracy: 0.9488 - val_loss: 0.1767\n",
      "Epoch 22/50\n",
      "\u001b[1m2338/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9743 - loss: 0.0570\n",
      "Epoch 22: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9743 - loss: 0.0570 - val_accuracy: 0.9458 - val_loss: 0.1899\n",
      "Epoch 23/50\n",
      "\u001b[1m2352/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9754 - loss: 0.0551\n",
      "Epoch 23: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9754 - loss: 0.0551 - val_accuracy: 0.9489 - val_loss: 0.1857\n",
      "Epoch 24/50\n",
      "\u001b[1m2344/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9761 - loss: 0.0526\n",
      "Epoch 24: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9761 - loss: 0.0526 - val_accuracy: 0.9482 - val_loss: 0.1960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "\u001b[1m2320/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.9767 - loss: 0.0520\n",
      "Epoch 25: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9768 - loss: 0.0520 - val_accuracy: 0.9491 - val_loss: 0.2042\n",
      "Epoch 26/50\n",
      "\u001b[1m2350/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9776 - loss: 0.0495\n",
      "Epoch 26: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9776 - loss: 0.0495 - val_accuracy: 0.9481 - val_loss: 0.2097\n",
      "Epoch 27/50\n",
      "\u001b[1m2336/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.9793 - loss: 0.0474\n",
      "Epoch 27: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9793 - loss: 0.0474 - val_accuracy: 0.9486 - val_loss: 0.2158\n",
      "Epoch 28/50\n",
      "\u001b[1m2333/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.9802 - loss: 0.0455\n",
      "Epoch 28: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9802 - loss: 0.0455 - val_accuracy: 0.9482 - val_loss: 0.2171\n",
      "Epoch 29/50\n",
      "\u001b[1m2333/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.9807 - loss: 0.0452\n",
      "Epoch 29: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9807 - loss: 0.0452 - val_accuracy: 0.9486 - val_loss: 0.2207\n",
      "Epoch 30/50\n",
      "\u001b[1m2324/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9797 - loss: 0.0473\n",
      "Epoch 30: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9797 - loss: 0.0473 - val_accuracy: 0.9477 - val_loss: 0.2212\n",
      "Epoch 31/50\n",
      "\u001b[1m2320/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9827 - loss: 0.0404\n",
      "Epoch 31: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9827 - loss: 0.0404 - val_accuracy: 0.9478 - val_loss: 0.2259\n",
      "Epoch 32/50\n",
      "\u001b[1m2315/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9830 - loss: 0.0409\n",
      "Epoch 32: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9829 - loss: 0.0409 - val_accuracy: 0.9461 - val_loss: 0.2197\n",
      "Epoch 33/50\n",
      "\u001b[1m2357/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.9836 - loss: 0.0386\n",
      "Epoch 33: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9836 - loss: 0.0386 - val_accuracy: 0.9469 - val_loss: 0.2356\n",
      "Epoch 34/50\n",
      "\u001b[1m2329/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 0.9845 - loss: 0.0363\n",
      "Epoch 34: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9845 - loss: 0.0363 - val_accuracy: 0.9470 - val_loss: 0.2323\n",
      "Epoch 35/50\n",
      "\u001b[1m2335/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9833 - loss: 0.0396\n",
      "Epoch 35: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9833 - loss: 0.0395 - val_accuracy: 0.9446 - val_loss: 0.2450\n",
      "Epoch 36/50\n",
      "\u001b[1m2354/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9848 - loss: 0.0349\n",
      "Epoch 36: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9848 - loss: 0.0349 - val_accuracy: 0.9486 - val_loss: 0.2270\n",
      "Epoch 37/50\n",
      "\u001b[1m2359/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9871 - loss: 0.0316\n",
      "Epoch 37: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9871 - loss: 0.0316 - val_accuracy: 0.9485 - val_loss: 0.2582\n",
      "Epoch 38/50\n",
      "\u001b[1m2328/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.9856 - loss: 0.0358\n",
      "Epoch 38: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9856 - loss: 0.0357 - val_accuracy: 0.9460 - val_loss: 0.2425\n",
      "Epoch 39/50\n",
      "\u001b[1m2343/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9870 - loss: 0.0326\n",
      "Epoch 39: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9870 - loss: 0.0326 - val_accuracy: 0.9444 - val_loss: 0.2389\n",
      "Epoch 40/50\n",
      "\u001b[1m2322/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.9859 - loss: 0.0356\n",
      "Epoch 40: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9859 - loss: 0.0355 - val_accuracy: 0.9467 - val_loss: 0.2349\n",
      "Epoch 41/50\n",
      "\u001b[1m2318/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9880 - loss: 0.0296 \n",
      "Epoch 41: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9880 - loss: 0.0296 - val_accuracy: 0.9441 - val_loss: 0.2431\n",
      "Epoch 42/50\n",
      "\u001b[1m2313/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9882 - loss: 0.0298\n",
      "Epoch 42: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9882 - loss: 0.0298 - val_accuracy: 0.9465 - val_loss: 0.2487\n",
      "Epoch 43/50\n",
      "\u001b[1m2359/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.9876 - loss: 0.0307\n",
      "Epoch 43: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9876 - loss: 0.0307 - val_accuracy: 0.9451 - val_loss: 0.2572\n",
      "Epoch 44/50\n",
      "\u001b[1m2347/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9879 - loss: 0.0307\n",
      "Epoch 44: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9879 - loss: 0.0307 - val_accuracy: 0.9415 - val_loss: 0.2455\n",
      "Epoch 45/50\n",
      "\u001b[1m2355/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9885 - loss: 0.0284\n",
      "Epoch 45: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9885 - loss: 0.0284 - val_accuracy: 0.9441 - val_loss: 0.2546\n",
      "Epoch 46/50\n",
      "\u001b[1m2340/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9877 - loss: 0.0304\n",
      "Epoch 46: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9877 - loss: 0.0303 - val_accuracy: 0.9427 - val_loss: 0.2547\n",
      "Epoch 47/50\n",
      "\u001b[1m2324/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9886 - loss: 0.0281\n",
      "Epoch 47: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9886 - loss: 0.0281 - val_accuracy: 0.9451 - val_loss: 0.2568\n",
      "Epoch 48/50\n",
      "\u001b[1m2354/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9904 - loss: 0.0240\n",
      "Epoch 48: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9904 - loss: 0.0240 - val_accuracy: 0.9433 - val_loss: 0.2702\n",
      "Epoch 49/50\n",
      "\u001b[1m2348/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9887 - loss: 0.0289\n",
      "Epoch 49: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9887 - loss: 0.0289 - val_accuracy: 0.9422 - val_loss: 0.2534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "\u001b[1m2351/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.9902 - loss: 0.0256\n",
      "Epoch 50: val_accuracy did not improve from 0.94972\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9902 - loss: 0.0256 - val_accuracy: 0.9459 - val_loss: 0.2644\n",
      "\u001b[1m1113/1113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed for NumPy and TensorFlow to ensure reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define the optimized model architecture based on hyperparameter tuning results\n",
    "model_optimized = Sequential([\n",
    "    Dense(192, input_shape=(X_train_scaled.shape[1],), activation='tanh'),  # First optimized layer\n",
    "    Dense(288, activation='relu'),  # Second optimized layer\n",
    "    Dense(128, activation='tanh'),  # Third optimized layer\n",
    "    Dense(416, activation='sigmoid'),  # Fourth optimized layer\n",
    "    Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model with the optimized learning rate\n",
    "model_optimized.compile(optimizer=Adam(learning_rate=0.000589358031504996), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Setup the ModelCheckpoint callback to save the best model\n",
    "model_checkpoint_optimized = ModelCheckpoint(\n",
    "    'best_model_optimized.keras',  # Specify .keras extension\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with validation split to monitor performance\n",
    "history_optimized = model_optimized.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,  # Consider adjusting based on performance and overfitting\n",
    "    batch_size=32,  # Batch size remains as per the base setup\n",
    "    callbacks=[model_checkpoint_optimized],  # Include the checkpoint in the callbacks\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Load the best model saved by ModelCheckpoint\n",
    "best_model_optimized = tf.keras.models.load_model('best_model_optimized.keras')\n",
    "\n",
    "# Use the best model to make predictions on the test set\n",
    "predictions_optimized = best_model_optimized.predict(X_test_scaled)\n",
    "predictions_optimized = (predictions_optimized > 0.5).astype(int)  # Convert probabilities to binary output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30a2cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine IDs with predictions for a submission\n",
    "results_df_optimized = pd.DataFrame({\n",
    "    'ID': test_ids,\n",
    "    'Overall_Experience': predictions_optimized.ravel()  # Adjust based on your model output structure\n",
    "})\n",
    "\n",
    "# Save or return results\n",
    "results_df_optimized.to_csv('submisson4.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
