{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b31a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic liabraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4110541c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/eyvone/anaconda3/lib/python3.11/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06ecf79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network related libaraies\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac37de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "X_train = pd.read_csv('X_train_no_miss.csv').drop(columns='ID', axis=1)\n",
    "y_train = pd.read_csv('Y_train.csv')\n",
    "X_test_initial = pd.read_csv('X_test_no_miss.csv')\n",
    "test_ids = X_test_initial['ID']\n",
    "X_test = X_test_initial.drop(columns='ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f937f539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gender', 'Customer_Type', 'Age', 'Type_Travel', 'Travel_Class',\n",
       "       'Travel_Distance', 'Departure_Delay_in_Mins', 'Arrival_Delay_in_Mins',\n",
       "       'Seat_Comfort', 'Seat_Class', 'Arrival_Time_Convenient', 'Catering',\n",
       "       'Platform_Location', 'Onboard_Wifi_Service', 'Onboard_Entertainment',\n",
       "       'Online_Support', 'Ease_of_Online_Booking', 'Onboard_Service',\n",
       "       'Legroom', 'Baggage_Handling', 'CheckIn_Service', 'Cleanliness',\n",
       "       'Online_Boarding'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce919b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35602 entries, 0 to 35601\n",
      "Data columns (total 23 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Gender                   35602 non-null  float64\n",
      " 1   Customer_Type            35602 non-null  float64\n",
      " 2   Age                      35602 non-null  float64\n",
      " 3   Type_Travel              35602 non-null  float64\n",
      " 4   Travel_Class             35602 non-null  int64  \n",
      " 5   Travel_Distance          35602 non-null  int64  \n",
      " 6   Departure_Delay_in_Mins  35602 non-null  float64\n",
      " 7   Arrival_Delay_in_Mins    35602 non-null  float64\n",
      " 8   Seat_Comfort             35602 non-null  float64\n",
      " 9   Seat_Class               35602 non-null  int64  \n",
      " 10  Arrival_Time_Convenient  35602 non-null  float64\n",
      " 11  Catering                 35602 non-null  float64\n",
      " 12  Platform_Location        35602 non-null  float64\n",
      " 13  Onboard_Wifi_Service     35602 non-null  float64\n",
      " 14  Onboard_Entertainment    35602 non-null  float64\n",
      " 15  Online_Support           35602 non-null  float64\n",
      " 16  Ease_of_Online_Booking   35602 non-null  float64\n",
      " 17  Onboard_Service          35602 non-null  float64\n",
      " 18  Legroom                  35602 non-null  float64\n",
      " 19  Baggage_Handling         35602 non-null  float64\n",
      " 20  CheckIn_Service          35602 non-null  float64\n",
      " 21  Cleanliness              35602 non-null  float64\n",
      " 22  Online_Boarding          35602 non-null  float64\n",
      "dtypes: float64(20), int64(3)\n",
      "memory usage: 6.2 MB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1dc76925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2159/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 256us/step - accuracy: 0.8628 - loss: 0.3147\n",
      "Epoch 1: val_accuracy improved from -inf to 0.92106, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325us/step - accuracy: 0.8657 - loss: 0.3086 - val_accuracy: 0.9211 - val_loss: 0.1950\n",
      "Epoch 2/50\n",
      "\u001b[1m2222/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 248us/step - accuracy: 0.9233 - loss: 0.1836\n",
      "Epoch 2: val_accuracy improved from 0.92106 to 0.93018, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 295us/step - accuracy: 0.9235 - loss: 0.1831 - val_accuracy: 0.9302 - val_loss: 0.1693\n",
      "Epoch 3/50\n",
      "\u001b[1m2323/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 237us/step - accuracy: 0.9328 - loss: 0.1599\n",
      "Epoch 3: val_accuracy improved from 0.93018 to 0.93510, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 284us/step - accuracy: 0.9328 - loss: 0.1599 - val_accuracy: 0.9351 - val_loss: 0.1565\n",
      "Epoch 4/50\n",
      "\u001b[1m2240/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 247us/step - accuracy: 0.9370 - loss: 0.1485\n",
      "Epoch 4: val_accuracy improved from 0.93510 to 0.93791, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301us/step - accuracy: 0.9371 - loss: 0.1483 - val_accuracy: 0.9379 - val_loss: 0.1501\n",
      "Epoch 5/50\n",
      "\u001b[1m2201/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 251us/step - accuracy: 0.9408 - loss: 0.1408\n",
      "Epoch 5: val_accuracy improved from 0.93791 to 0.93855, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300us/step - accuracy: 0.9409 - loss: 0.1406 - val_accuracy: 0.9385 - val_loss: 0.1461\n",
      "Epoch 6/50\n",
      "\u001b[1m2303/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 239us/step - accuracy: 0.9432 - loss: 0.1347\n",
      "Epoch 6: val_accuracy improved from 0.93855 to 0.94045, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287us/step - accuracy: 0.9432 - loss: 0.1346 - val_accuracy: 0.9405 - val_loss: 0.1423\n",
      "Epoch 7/50\n",
      "\u001b[1m2232/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 247us/step - accuracy: 0.9450 - loss: 0.1299\n",
      "Epoch 7: val_accuracy improved from 0.94045 to 0.94225, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297us/step - accuracy: 0.9451 - loss: 0.1297 - val_accuracy: 0.9423 - val_loss: 0.1397\n",
      "Epoch 8/50\n",
      "\u001b[1m2184/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 253us/step - accuracy: 0.9467 - loss: 0.1262\n",
      "Epoch 8: val_accuracy improved from 0.94225 to 0.94310, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299us/step - accuracy: 0.9467 - loss: 0.1259 - val_accuracy: 0.9431 - val_loss: 0.1365\n",
      "Epoch 9/50\n",
      "\u001b[1m2318/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 238us/step - accuracy: 0.9467 - loss: 0.1225\n",
      "Epoch 9: val_accuracy improved from 0.94310 to 0.94432, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 284us/step - accuracy: 0.9467 - loss: 0.1225 - val_accuracy: 0.9443 - val_loss: 0.1353\n",
      "Epoch 10/50\n",
      "\u001b[1m2321/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 238us/step - accuracy: 0.9488 - loss: 0.1196\n",
      "Epoch 10: val_accuracy did not improve from 0.94432\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 284us/step - accuracy: 0.9488 - loss: 0.1196 - val_accuracy: 0.9442 - val_loss: 0.1329\n",
      "Epoch 11/50\n",
      "\u001b[1m2323/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 237us/step - accuracy: 0.9493 - loss: 0.1173\n",
      "Epoch 11: val_accuracy improved from 0.94432 to 0.94512, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 285us/step - accuracy: 0.9493 - loss: 0.1173 - val_accuracy: 0.9451 - val_loss: 0.1319\n",
      "Epoch 12/50\n",
      "\u001b[1m2217/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 249us/step - accuracy: 0.9508 - loss: 0.1151\n",
      "Epoch 12: val_accuracy improved from 0.94512 to 0.94554, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298us/step - accuracy: 0.9508 - loss: 0.1149 - val_accuracy: 0.9455 - val_loss: 0.1294\n",
      "Epoch 13/50\n",
      "\u001b[1m2205/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 250us/step - accuracy: 0.9515 - loss: 0.1128\n",
      "Epoch 13: val_accuracy improved from 0.94554 to 0.94596, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296us/step - accuracy: 0.9516 - loss: 0.1126 - val_accuracy: 0.9460 - val_loss: 0.1286\n",
      "Epoch 14/50\n",
      "\u001b[1m2300/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 240us/step - accuracy: 0.9520 - loss: 0.1112\n",
      "Epoch 14: val_accuracy improved from 0.94596 to 0.94665, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287us/step - accuracy: 0.9521 - loss: 0.1111 - val_accuracy: 0.9467 - val_loss: 0.1276\n",
      "Epoch 15/50\n",
      "\u001b[1m2300/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 240us/step - accuracy: 0.9531 - loss: 0.1096\n",
      "Epoch 15: val_accuracy improved from 0.94665 to 0.94739, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287us/step - accuracy: 0.9531 - loss: 0.1095 - val_accuracy: 0.9474 - val_loss: 0.1263\n",
      "Epoch 16/50\n",
      "\u001b[1m2260/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 244us/step - accuracy: 0.9532 - loss: 0.1080\n",
      "Epoch 16: val_accuracy did not improve from 0.94739\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289us/step - accuracy: 0.9532 - loss: 0.1079 - val_accuracy: 0.9470 - val_loss: 0.1273\n",
      "Epoch 17/50\n",
      "\u001b[1m2289/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 241us/step - accuracy: 0.9543 - loss: 0.1066\n",
      "Epoch 17: val_accuracy improved from 0.94739 to 0.94745, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 288us/step - accuracy: 0.9543 - loss: 0.1065 - val_accuracy: 0.9474 - val_loss: 0.1268\n",
      "Epoch 18/50\n",
      "\u001b[1m2280/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 242us/step - accuracy: 0.9543 - loss: 0.1055\n",
      "Epoch 18: val_accuracy improved from 0.94745 to 0.94787, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289us/step - accuracy: 0.9543 - loss: 0.1055 - val_accuracy: 0.9479 - val_loss: 0.1263\n",
      "Epoch 19/50\n",
      "\u001b[1m2270/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 243us/step - accuracy: 0.9553 - loss: 0.1042\n",
      "Epoch 19: val_accuracy improved from 0.94787 to 0.94835, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289us/step - accuracy: 0.9553 - loss: 0.1041 - val_accuracy: 0.9483 - val_loss: 0.1263\n",
      "Epoch 20/50\n",
      "\u001b[1m2345/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 235us/step - accuracy: 0.9560 - loss: 0.1027\n",
      "Epoch 20: val_accuracy did not improve from 0.94835\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 280us/step - accuracy: 0.9560 - loss: 0.1027 - val_accuracy: 0.9481 - val_loss: 0.1260\n",
      "Epoch 21/50\n",
      "\u001b[1m2232/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 247us/step - accuracy: 0.9562 - loss: 0.1020\n",
      "Epoch 21: val_accuracy did not improve from 0.94835\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 294us/step - accuracy: 0.9562 - loss: 0.1019 - val_accuracy: 0.9475 - val_loss: 0.1262\n",
      "Epoch 22/50\n",
      "\u001b[1m2245/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 246us/step - accuracy: 0.9563 - loss: 0.1009\n",
      "Epoch 22: val_accuracy did not improve from 0.94835\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291us/step - accuracy: 0.9563 - loss: 0.1008 - val_accuracy: 0.9481 - val_loss: 0.1260\n",
      "Epoch 23/50\n",
      "\u001b[1m2252/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 245us/step - accuracy: 0.9563 - loss: 0.1009\n",
      "Epoch 23: val_accuracy improved from 0.94835 to 0.94946, saving model to best_model.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 293us/step - accuracy: 0.9563 - loss: 0.1008 - val_accuracy: 0.9495 - val_loss: 0.1258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "\u001b[1m2220/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 248us/step - accuracy: 0.9575 - loss: 0.0994\n",
      "Epoch 24: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 294us/step - accuracy: 0.9575 - loss: 0.0993 - val_accuracy: 0.9486 - val_loss: 0.1259\n",
      "Epoch 25/50\n",
      "\u001b[1m2243/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 246us/step - accuracy: 0.9571 - loss: 0.0985\n",
      "Epoch 25: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 293us/step - accuracy: 0.9571 - loss: 0.0984 - val_accuracy: 0.9491 - val_loss: 0.1262\n",
      "Epoch 26/50\n",
      "\u001b[1m2197/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 251us/step - accuracy: 0.9574 - loss: 0.0978\n",
      "Epoch 26: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299us/step - accuracy: 0.9574 - loss: 0.0977 - val_accuracy: 0.9492 - val_loss: 0.1262\n",
      "Epoch 27/50\n",
      "\u001b[1m2156/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 256us/step - accuracy: 0.9577 - loss: 0.0972\n",
      "Epoch 27: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300us/step - accuracy: 0.9577 - loss: 0.0970 - val_accuracy: 0.9479 - val_loss: 0.1273\n",
      "Epoch 28/50\n",
      "\u001b[1m2255/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 245us/step - accuracy: 0.9583 - loss: 0.0961\n",
      "Epoch 28: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291us/step - accuracy: 0.9583 - loss: 0.0961 - val_accuracy: 0.9486 - val_loss: 0.1274\n",
      "Epoch 29/50\n",
      "\u001b[1m2237/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 247us/step - accuracy: 0.9584 - loss: 0.0955\n",
      "Epoch 29: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291us/step - accuracy: 0.9584 - loss: 0.0954 - val_accuracy: 0.9474 - val_loss: 0.1286\n",
      "Epoch 30/50\n",
      "\u001b[1m2293/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 240us/step - accuracy: 0.9589 - loss: 0.0948\n",
      "Epoch 30: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287us/step - accuracy: 0.9589 - loss: 0.0947 - val_accuracy: 0.9473 - val_loss: 0.1291\n",
      "Epoch 31/50\n",
      "\u001b[1m2259/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 244us/step - accuracy: 0.9580 - loss: 0.0954\n",
      "Epoch 31: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289us/step - accuracy: 0.9580 - loss: 0.0953 - val_accuracy: 0.9474 - val_loss: 0.1285\n",
      "Epoch 32/50\n",
      "\u001b[1m2240/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 246us/step - accuracy: 0.9593 - loss: 0.0938\n",
      "Epoch 32: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291us/step - accuracy: 0.9593 - loss: 0.0937 - val_accuracy: 0.9479 - val_loss: 0.1307\n",
      "Epoch 33/50\n",
      "\u001b[1m2219/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 248us/step - accuracy: 0.9598 - loss: 0.0932\n",
      "Epoch 33: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 293us/step - accuracy: 0.9598 - loss: 0.0931 - val_accuracy: 0.9465 - val_loss: 0.1326\n",
      "Epoch 34/50\n",
      "\u001b[1m2273/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 243us/step - accuracy: 0.9600 - loss: 0.0929\n",
      "Epoch 34: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 288us/step - accuracy: 0.9600 - loss: 0.0928 - val_accuracy: 0.9460 - val_loss: 0.1327\n",
      "Epoch 35/50\n",
      "\u001b[1m2276/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 242us/step - accuracy: 0.9602 - loss: 0.0918\n",
      "Epoch 35: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287us/step - accuracy: 0.9602 - loss: 0.0918 - val_accuracy: 0.9453 - val_loss: 0.1342\n",
      "Epoch 36/50\n",
      "\u001b[1m2240/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 246us/step - accuracy: 0.9601 - loss: 0.0919\n",
      "Epoch 36: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 292us/step - accuracy: 0.9601 - loss: 0.0918 - val_accuracy: 0.9460 - val_loss: 0.1320\n",
      "Epoch 37/50\n",
      "\u001b[1m2198/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 251us/step - accuracy: 0.9607 - loss: 0.0908\n",
      "Epoch 37: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296us/step - accuracy: 0.9607 - loss: 0.0907 - val_accuracy: 0.9464 - val_loss: 0.1351\n",
      "Epoch 38/50\n",
      "\u001b[1m2194/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 274us/step - accuracy: 0.9608 - loss: 0.0909\n",
      "Epoch 38: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 318us/step - accuracy: 0.9609 - loss: 0.0908 - val_accuracy: 0.9456 - val_loss: 0.1338\n",
      "Epoch 39/50\n",
      "\u001b[1m2315/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 260us/step - accuracy: 0.9612 - loss: 0.0905\n",
      "Epoch 39: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309us/step - accuracy: 0.9612 - loss: 0.0905 - val_accuracy: 0.9464 - val_loss: 0.1348\n",
      "Epoch 40/50\n",
      "\u001b[1m2249/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 245us/step - accuracy: 0.9615 - loss: 0.0896\n",
      "Epoch 40: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290us/step - accuracy: 0.9615 - loss: 0.0895 - val_accuracy: 0.9464 - val_loss: 0.1344\n",
      "Epoch 41/50\n",
      "\u001b[1m2277/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 242us/step - accuracy: 0.9616 - loss: 0.0890\n",
      "Epoch 41: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287us/step - accuracy: 0.9617 - loss: 0.0889 - val_accuracy: 0.9461 - val_loss: 0.1341\n",
      "Epoch 42/50\n",
      "\u001b[1m2233/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 247us/step - accuracy: 0.9620 - loss: 0.0891\n",
      "Epoch 42: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 292us/step - accuracy: 0.9620 - loss: 0.0890 - val_accuracy: 0.9460 - val_loss: 0.1341\n",
      "Epoch 43/50\n",
      "\u001b[1m2270/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 243us/step - accuracy: 0.9625 - loss: 0.0881\n",
      "Epoch 43: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 288us/step - accuracy: 0.9625 - loss: 0.0880 - val_accuracy: 0.9466 - val_loss: 0.1353\n",
      "Epoch 44/50\n",
      "\u001b[1m2260/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 244us/step - accuracy: 0.9623 - loss: 0.0882\n",
      "Epoch 44: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290us/step - accuracy: 0.9623 - loss: 0.0881 - val_accuracy: 0.9456 - val_loss: 0.1367\n",
      "Epoch 45/50\n",
      "\u001b[1m2320/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 238us/step - accuracy: 0.9629 - loss: 0.0871\n",
      "Epoch 45: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 282us/step - accuracy: 0.9630 - loss: 0.0871 - val_accuracy: 0.9466 - val_loss: 0.1349\n",
      "Epoch 46/50\n",
      "\u001b[1m2257/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 244us/step - accuracy: 0.9626 - loss: 0.0875\n",
      "Epoch 46: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289us/step - accuracy: 0.9626 - loss: 0.0874 - val_accuracy: 0.9473 - val_loss: 0.1355\n",
      "Epoch 47/50\n",
      "\u001b[1m2172/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 231us/step - accuracy: 0.9627 - loss: 0.0871\n",
      "Epoch 47: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275us/step - accuracy: 0.9627 - loss: 0.0870 - val_accuracy: 0.9463 - val_loss: 0.1352\n",
      "Epoch 48/50\n",
      "\u001b[1m2189/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 229us/step - accuracy: 0.9632 - loss: 0.0865\n",
      "Epoch 48: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 274us/step - accuracy: 0.9632 - loss: 0.0864 - val_accuracy: 0.9462 - val_loss: 0.1358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "\u001b[1m2340/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 236us/step - accuracy: 0.9627 - loss: 0.0859\n",
      "Epoch 49: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 280us/step - accuracy: 0.9627 - loss: 0.0859 - val_accuracy: 0.9457 - val_loss: 0.1385\n",
      "Epoch 50/50\n",
      "\u001b[1m2300/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 240us/step - accuracy: 0.9629 - loss: 0.0867\n",
      "Epoch 50: val_accuracy did not improve from 0.94946\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 284us/step - accuracy: 0.9629 - loss: 0.0867 - val_accuracy: 0.9455 - val_loss: 0.1363\n",
      "\u001b[1m1113/1113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191us/step\n"
     ]
    }
   ],
   "source": [
    "# Scale the features (fit on X_train and transform both X_train and X_test)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Set a random seed for NumPy and TensorFlow to ensure reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(X_train_scaled.shape[1],), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Setup the ModelCheckpoint callback to save the best model\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',  # Specify .keras extension\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with validation split to monitor performance\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[model_checkpoint],  # Include the checkpoint in the callbacks\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Load the best model saved by ModelCheckpoint\n",
    "best_model = tf.keras.models.load_model('best_model.keras')\n",
    "\n",
    "# Use the best model to make predictions on the test set\n",
    "predictions = best_model.predict(X_test_scaled)\n",
    "predictions = (predictions > 0.5).astype(int)  # Convert probabilities to binary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00de308e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff07f890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.9447446465492249\n",
      "Validation score: 0.946651816368103\n",
      "Validation score: 0.943314254283905\n",
      "Validation score: 0.9461750388145447\n",
      "Validation score: 0.9465960264205933\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Set a random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "# Prepare cross-validation with 5 splits, shuffling, and a specific random state\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, val_index in kf.split(X_train_scaled):\n",
    "    X_train_k, X_val_k = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "    y_train_k, y_val_k = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Build and compile the model (should be done inside the loop)\n",
    "    model_val = Sequential()\n",
    "    model_val.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model_val.add(Dense(32, activation='relu'))\n",
    "    model_val.add(Dense(1, activation='sigmoid'))\n",
    "    model_val.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model_val.fit(X_train_k, y_train_k, epochs=50, batch_size=32, verbose=0)  # Adjust epochs, batch size as necessary\n",
    "    \n",
    "    # Evaluate the model\n",
    "    score_val = model_val.evaluate(X_val_k, y_val_k, verbose=0)\n",
    "    print(f'Validation score: {score_val[1]}')  # score[1] should be the accuracy if using 'metrics=['accuracy']'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be8652f",
   "metadata": {},
   "source": [
    "**Interpretation of Validation Scores**\n",
    "\n",
    "- **High Accuracy Scores**: The validation scores are all above 94%, which suggests that the model is performing very well across different subsets of the training data. This is a positive sign that the model is not overly fitted to a particular part of the training data.\n",
    "- **Consistency Across Folds**: The slight variation in accuracy scores between different folds indicates that the model's performance is stable across different splits of the data. This stability is crucial for confirming that the model is reliable and should perform similarly on new, similar data.\n",
    "- **Model Robustness**: These results suggest that the neural network architecture, including the number of layers, nodes, and the choice of activation functions, is well-suited for this task. The use of ReLU activation in hidden layers and sigmoid in the output layer for binary classification appears to be effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e882c8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1113/1113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201us/step\n"
     ]
    }
   ],
   "source": [
    "# Predict the result\n",
    "predictions = model.predict(X_test_scaled)\n",
    "predictions = (predictions > 0.5).astype(int)  # Convert probabilities to binary output\n",
    "\n",
    "# Combine IDs with predictions for a submission\n",
    "results_df = pd.DataFrame({\n",
    "    'ID': test_ids,\n",
    "    'Overall_Experience': predictions.ravel()  # Adjust based on your model output structure\n",
    "})\n",
    "\n",
    "# Save or return results\n",
    "results_df.to_csv('submisson1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "391dcb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Overall_Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99900001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99900002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99900003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99900004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99900005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35597</th>\n",
       "      <td>99935598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35598</th>\n",
       "      <td>99935599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35599</th>\n",
       "      <td>99935600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35600</th>\n",
       "      <td>99935601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35601</th>\n",
       "      <td>99935602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35602 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  Overall_Experience\n",
       "0      99900001                   1\n",
       "1      99900002                   1\n",
       "2      99900003                   1\n",
       "3      99900004                   0\n",
       "4      99900005                   1\n",
       "...         ...                 ...\n",
       "35597  99935598                   0\n",
       "35598  99935599                   1\n",
       "35599  99935600                   0\n",
       "35600  99935601                   1\n",
       "35601  99935602                   0\n",
       "\n",
       "[35602 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57c66c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35602, 24)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_initial.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64de02b6",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d092f32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Obtaining dependency information for keras-tuner from https://files.pythonhosted.org/packages/db/5d/945296512980b0827e93418514c8be9236baa6f0a1e8ca8be3a2026665b0/keras_tuner-1.4.7-py3-none-any.whl.metadata\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras-tuner) (3.3.2)\n",
      "Requirement already satisfied: packaging in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras-tuner) (23.1)\n",
      "Requirement already satisfied: requests in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras-tuner) (2.31.0)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Obtaining dependency information for kt-legacy from https://files.pythonhosted.org/packages/16/53/aca9f36da2516db008017db85a1f3cafaee0efc5fc7a25d94c909651792f/kt_legacy-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: absl-py in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: numpy in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (1.24.3)\n",
      "Requirement already satisfied: rich in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (3.11.0)\n",
      "Requirement already satisfied: optree in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from keras->keras-tuner) (0.3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from requests->keras-tuner) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from requests->keras-tuner) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from optree->keras->keras-tuner) (4.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from rich->keras->keras-tuner) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from rich->keras->keras-tuner) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/eyvone/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.0)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5e431cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 37s]\n",
      "val_accuracy: 0.9423871636390686\n",
      "\n",
      "Best val_accuracy So Far: 0.9486649632453918\n",
      "Total elapsed time: 00h 15m 06s\n",
      "\n",
      "The best number of layers: 4\n",
      "The best number of units per layer: [480, 416, 192, 160]\n",
      "The best activations per layer: ['relu', 'tanh', 'tanh', 'relu']\n",
      "The best learning rate for the optimizer: 0.000589358031504996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner import HyperModel\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "class MyHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "    \n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.InputLayer(input_shape=self.input_shape))\n",
    "        \n",
    "        # Tune the number of layers, now allowing up to 5 dense layers\n",
    "        for i in range(hp.Int('num_layers', 1, 5)): \n",
    "            model.add(layers.Dense(\n",
    "                units=hp.Int('units_' + str(i), min_value=32, max_value=512, step=32),\n",
    "                activation=hp.Choice('activation_' + str(i), values=['relu', 'tanh', 'sigmoid'])\n",
    "            ))\n",
    "        \n",
    "        model.add(layers.Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(\n",
    "                hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "# Assuming X_train_scaled and y_train are already defined\n",
    "input_shape = (X_train_scaled.shape[1],)\n",
    "\n",
    "hypermodel = MyHyperModel(input_shape=input_shape)\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=20,  # Set a reasonable number of trials to find the best hyperparameters\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',  # Directory to store logs\n",
    "    project_name='keras_tuner_demo'\n",
    ")\n",
    "\n",
    "# Start tuning\n",
    "tuner.search(X_train_scaled, y_train, epochs=10, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The best number of layers: {best_hps.get('num_layers')}\n",
    "The best number of units per layer: {[best_hps.get('units_' + str(i)) for i in range(best_hps.get('num_layers'))]}\n",
    "The best activations per layer: {[best_hps.get('activation_' + str(i)) for i in range(best_hps.get('num_layers'))]}\n",
    "The best learning rate for the optimizer: {best_hps.get('learning_rate')}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb11d69",
   "metadata": {},
   "source": [
    "### Optimized Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a078788c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2349/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8931 - loss: 0.2475\n",
      "Epoch 1: val_accuracy improved from -inf to 0.93150, saving model to best_model_optimized.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8932 - loss: 0.2473 - val_accuracy: 0.9315 - val_loss: 0.1643\n",
      "Epoch 2/50\n",
      "\u001b[1m2354/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9336 - loss: 0.1557\n",
      "Epoch 2: val_accuracy improved from 0.93150 to 0.93961, saving model to best_model_optimized.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9336 - loss: 0.1557 - val_accuracy: 0.9396 - val_loss: 0.1422\n",
      "Epoch 3/50\n",
      "\u001b[1m2344/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9439 - loss: 0.1328\n",
      "Epoch 3: val_accuracy improved from 0.93961 to 0.94427, saving model to best_model_optimized.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9439 - loss: 0.1328 - val_accuracy: 0.9443 - val_loss: 0.1328\n",
      "Epoch 4/50\n",
      "\u001b[1m2342/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9481 - loss: 0.1209\n",
      "Epoch 4: val_accuracy improved from 0.94427 to 0.94702, saving model to best_model_optimized.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9482 - loss: 0.1208 - val_accuracy: 0.9470 - val_loss: 0.1287\n",
      "Epoch 5/50\n",
      "\u001b[1m2352/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9512 - loss: 0.1137\n",
      "Epoch 5: val_accuracy improved from 0.94702 to 0.94734, saving model to best_model_optimized.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9512 - loss: 0.1137 - val_accuracy: 0.9473 - val_loss: 0.1270\n",
      "Epoch 6/50\n",
      "\u001b[1m2345/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9533 - loss: 0.1088\n",
      "Epoch 6: val_accuracy improved from 0.94734 to 0.94787, saving model to best_model_optimized.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9533 - loss: 0.1088 - val_accuracy: 0.9479 - val_loss: 0.1253\n",
      "Epoch 7/50\n",
      "\u001b[1m2339/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9550 - loss: 0.1042\n",
      "Epoch 7: val_accuracy improved from 0.94787 to 0.94808, saving model to best_model_optimized.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9551 - loss: 0.1041 - val_accuracy: 0.9481 - val_loss: 0.1254\n",
      "Epoch 8/50\n",
      "\u001b[1m2353/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9576 - loss: 0.0985\n",
      "Epoch 8: val_accuracy did not improve from 0.94808\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9576 - loss: 0.0985 - val_accuracy: 0.9467 - val_loss: 0.1324\n",
      "Epoch 9/50\n",
      "\u001b[1m2342/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9582 - loss: 0.0953\n",
      "Epoch 9: val_accuracy did not improve from 0.94808\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9582 - loss: 0.0953 - val_accuracy: 0.9476 - val_loss: 0.1323\n",
      "Epoch 10/50\n",
      "\u001b[1m2357/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9591 - loss: 0.0922\n",
      "Epoch 10: val_accuracy improved from 0.94808 to 0.94962, saving model to best_model_optimized.keras\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9591 - loss: 0.0922 - val_accuracy: 0.9496 - val_loss: 0.1293\n",
      "Epoch 11/50\n",
      "\u001b[1m2350/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9617 - loss: 0.0882\n",
      "Epoch 11: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9617 - loss: 0.0882 - val_accuracy: 0.9494 - val_loss: 0.1350\n",
      "Epoch 12/50\n",
      "\u001b[1m2336/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9620 - loss: 0.0860\n",
      "Epoch 12: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9620 - loss: 0.0860 - val_accuracy: 0.9473 - val_loss: 0.1453\n",
      "Epoch 13/50\n",
      "\u001b[1m2348/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9628 - loss: 0.0833\n",
      "Epoch 13: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9628 - loss: 0.0833 - val_accuracy: 0.9480 - val_loss: 0.1395\n",
      "Epoch 14/50\n",
      "\u001b[1m2343/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9649 - loss: 0.0781\n",
      "Epoch 14: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9649 - loss: 0.0781 - val_accuracy: 0.9486 - val_loss: 0.1323\n",
      "Epoch 15/50\n",
      "\u001b[1m2358/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 0.0744\n",
      "Epoch 15: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 0.0744 - val_accuracy: 0.9481 - val_loss: 0.1410\n",
      "Epoch 16/50\n",
      "\u001b[1m2336/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 0.0739\n",
      "Epoch 16: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 0.0739 - val_accuracy: 0.9467 - val_loss: 0.1528\n",
      "Epoch 17/50\n",
      "\u001b[1m2359/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.0695\n",
      "Epoch 17: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.0695 - val_accuracy: 0.9468 - val_loss: 0.1534\n",
      "Epoch 18/50\n",
      "\u001b[1m2345/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.0670\n",
      "Epoch 18: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.0670 - val_accuracy: 0.9483 - val_loss: 0.1613\n",
      "Epoch 19/50\n",
      "\u001b[1m2340/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9710 - loss: 0.0661\n",
      "Epoch 19: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9710 - loss: 0.0661 - val_accuracy: 0.9478 - val_loss: 0.1702\n",
      "Epoch 20/50\n",
      "\u001b[1m2345/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9722 - loss: 0.0621\n",
      "Epoch 20: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9722 - loss: 0.0620 - val_accuracy: 0.9489 - val_loss: 0.1630\n",
      "Epoch 21/50\n",
      "\u001b[1m2332/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9739 - loss: 0.0587\n",
      "Epoch 21: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9739 - loss: 0.0586 - val_accuracy: 0.9454 - val_loss: 0.1773\n",
      "Epoch 22/50\n",
      "\u001b[1m2340/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9743 - loss: 0.0580\n",
      "Epoch 22: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9743 - loss: 0.0580 - val_accuracy: 0.9471 - val_loss: 0.1715\n",
      "Epoch 23/50\n",
      "\u001b[1m2335/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9750 - loss: 0.0561\n",
      "Epoch 23: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9750 - loss: 0.0561 - val_accuracy: 0.9464 - val_loss: 0.1847\n",
      "Epoch 24/50\n",
      "\u001b[1m2349/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.0535\n",
      "Epoch 24: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.0535 - val_accuracy: 0.9451 - val_loss: 0.2013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "\u001b[1m2357/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9773 - loss: 0.0514\n",
      "Epoch 25: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9773 - loss: 0.0514 - val_accuracy: 0.9465 - val_loss: 0.1839\n",
      "Epoch 26/50\n",
      "\u001b[1m2337/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9782 - loss: 0.0504\n",
      "Epoch 26: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9782 - loss: 0.0503 - val_accuracy: 0.9460 - val_loss: 0.1996\n",
      "Epoch 27/50\n",
      "\u001b[1m2340/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9800 - loss: 0.0464\n",
      "Epoch 27: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9800 - loss: 0.0464 - val_accuracy: 0.9440 - val_loss: 0.2109\n",
      "Epoch 28/50\n",
      "\u001b[1m2339/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.0461\n",
      "Epoch 28: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 0.0461 - val_accuracy: 0.9434 - val_loss: 0.2276\n",
      "Epoch 29/50\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0433\n",
      "Epoch 29: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0433 - val_accuracy: 0.9434 - val_loss: 0.2214\n",
      "Epoch 30/50\n",
      "\u001b[1m2336/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9818 - loss: 0.0420\n",
      "Epoch 30: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9818 - loss: 0.0420 - val_accuracy: 0.9458 - val_loss: 0.2265\n",
      "Epoch 31/50\n",
      "\u001b[1m2330/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9832 - loss: 0.0394\n",
      "Epoch 31: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9832 - loss: 0.0394 - val_accuracy: 0.9460 - val_loss: 0.2352\n",
      "Epoch 32/50\n",
      "\u001b[1m2332/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0359\n",
      "Epoch 32: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0359 - val_accuracy: 0.9469 - val_loss: 0.2301\n",
      "Epoch 33/50\n",
      "\u001b[1m2336/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9851 - loss: 0.0362\n",
      "Epoch 33: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9852 - loss: 0.0362 - val_accuracy: 0.9454 - val_loss: 0.2363\n",
      "Epoch 34/50\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0346\n",
      "Epoch 34: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0346 - val_accuracy: 0.9428 - val_loss: 0.2636\n",
      "Epoch 35/50\n",
      "\u001b[1m2340/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0363\n",
      "Epoch 35: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0362 - val_accuracy: 0.9450 - val_loss: 0.2511\n",
      "Epoch 36/50\n",
      "\u001b[1m2347/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9876 - loss: 0.0312\n",
      "Epoch 36: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9876 - loss: 0.0312 - val_accuracy: 0.9447 - val_loss: 0.2560\n",
      "Epoch 37/50\n",
      "\u001b[1m2338/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0290\n",
      "Epoch 37: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0291 - val_accuracy: 0.9452 - val_loss: 0.2628\n",
      "Epoch 38/50\n",
      "\u001b[1m2342/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.0293\n",
      "Epoch 38: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.0293 - val_accuracy: 0.9404 - val_loss: 0.2962\n",
      "Epoch 39/50\n",
      "\u001b[1m2343/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0290\n",
      "Epoch 39: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0290 - val_accuracy: 0.9450 - val_loss: 0.2936\n",
      "Epoch 40/50\n",
      "\u001b[1m2335/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0290\n",
      "Epoch 40: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0290 - val_accuracy: 0.9447 - val_loss: 0.2965\n",
      "Epoch 41/50\n",
      "\u001b[1m2330/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9893 - loss: 0.0273\n",
      "Epoch 41: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9893 - loss: 0.0273 - val_accuracy: 0.9455 - val_loss: 0.2792\n",
      "Epoch 42/50\n",
      "\u001b[1m2358/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.0287\n",
      "Epoch 42: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.0287 - val_accuracy: 0.9459 - val_loss: 0.2866\n",
      "Epoch 43/50\n",
      "\u001b[1m2338/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0229\n",
      "Epoch 43: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0229 - val_accuracy: 0.9450 - val_loss: 0.2885\n",
      "Epoch 44/50\n",
      "\u001b[1m2358/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9905 - loss: 0.0238\n",
      "Epoch 44: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9905 - loss: 0.0238 - val_accuracy: 0.9459 - val_loss: 0.2911\n",
      "Epoch 45/50\n",
      "\u001b[1m2338/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0241\n",
      "Epoch 45: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0241 - val_accuracy: 0.9438 - val_loss: 0.2897\n",
      "Epoch 46/50\n",
      "\u001b[1m2348/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0243\n",
      "Epoch 46: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0243 - val_accuracy: 0.9474 - val_loss: 0.2837\n",
      "Epoch 47/50\n",
      "\u001b[1m2359/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0206\n",
      "Epoch 47: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0206 - val_accuracy: 0.9459 - val_loss: 0.3119\n",
      "Epoch 48/50\n",
      "\u001b[1m2348/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0234\n",
      "Epoch 48: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0235 - val_accuracy: 0.9454 - val_loss: 0.2828\n",
      "Epoch 49/50\n",
      "\u001b[1m2336/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0201\n",
      "Epoch 49: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0201 - val_accuracy: 0.9458 - val_loss: 0.3026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "\u001b[1m2333/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9911 - loss: 0.0229\n",
      "Epoch 50: val_accuracy did not improve from 0.94962\n",
      "\u001b[1m2360/2360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0229 - val_accuracy: 0.9452 - val_loss: 0.3201\n",
      "\u001b[1m1113/1113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed for NumPy and TensorFlow to ensure reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define the optimized model architecture based on hyperparameter tuning results\n",
    "model_optimized = Sequential([\n",
    "    Dense(480, input_shape=(X_train_scaled.shape[1],), activation='relu'),  # First optimized layer\n",
    "    Dense(416, activation='tanh'),  # Second optimized layer\n",
    "    Dense(192, activation='tanh'),  # Third optimized layer\n",
    "    Dense(160, activation='relu'),  # Fourth optimized layer\n",
    "    Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model with the optimized learning rate\n",
    "model_optimized.compile(optimizer=Adam(learning_rate=0.000589358031504996), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Setup the ModelCheckpoint callback to save the best model\n",
    "model_checkpoint_optimized = ModelCheckpoint(\n",
    "    'best_model_optimized.keras',  # Specify .keras extension\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with validation split to monitor performance\n",
    "history_optimized = model_optimized.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,  # Consider adjusting based on performance and overfitting\n",
    "    batch_size=32,  # Batch size remains as per the base setup\n",
    "    callbacks=[model_checkpoint_optimized],  # Include the checkpoint in the callbacks\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Load the best model saved by ModelCheckpoint\n",
    "best_model_optimized = tf.keras.models.load_model('best_model_optimized.keras')\n",
    "\n",
    "# Use the best model to make predictions on the test set\n",
    "predictions_optimized = best_model_optimized.predict(X_test_scaled)\n",
    "predictions_optimized = (predictions_optimized > 0.5).astype(int)  # Convert probabilities to binary output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30a2cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine IDs with predictions for a submission\n",
    "results_df_optimized = pd.DataFrame({\n",
    "    'ID': test_ids,\n",
    "    'Overall_Experience': predictions_optimized.ravel()  # Adjust based on your model output structure\n",
    "})\n",
    "\n",
    "# Save or return results\n",
    "results_df_optimized.to_csv('submisson2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
